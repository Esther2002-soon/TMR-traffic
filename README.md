# Traffic-Aware Multi-Degradation Restoration
éš¨è‘—æ™ºæ…§äº¤é€šèˆ‡æ™ºæ…§åŸå¸‚çš„ç™¼å±•ï¼Œäº¤é€šå ´åŸŸä¸­è»Šè¼‰æ”å½±æ©Ÿï¼ˆvehicle-mounted cameraï¼‰èˆ‡é“è·¯ç›£è¦–å™¨å·²æˆç‚ºé“è·¯å®‰å…¨èˆ‡äº¤é€šç®¡ç†çš„é‡è¦åŸºç¤ã€‚ç„¶è€Œï¼Œå¤œé–“ä¸‹é›¨ç’°å¢ƒå¾€å¾€é€ æˆå½±åƒå“è³ªæƒ¡åŒ–ï¼ŒåŒ…æ‹¬ä½å…‰ç…§ã€é›¨çµ²ã€é›¨æ»´é®æ“‹èˆ‡é‹å‹•æ¨¡ç³Šç­‰å•é¡Œï¼Œå½±éŸ¿é§•é§›è¼”åŠ©èˆ‡ç›£æ§ç³»çµ±çš„å¯é æ€§ã€‚å‚³çµ±æ–¹æ³•å¤šåƒ…é‡å°å–®ä¸€é€€åŒ–ï¼ˆå¦‚å»é›¨æˆ–å¢äº®ï¼‰ï¼Œç¼ºä¹æ•´åˆèƒ½åŠ›ï¼Œé›£ä»¥æ»¿è¶³çœŸå¯¦å ´æ™¯éœ€æ±‚ã€‚æœ¬å°ˆé¡ŒåŸºæ–¼æ­¤å‹•æ©Ÿï¼Œæå‡ºäº¤é€šå ´åŸŸå¤šé‡é€€åŒ–å½±åƒæ™ºæ…§å¾©åŸç³»çµ±ã€‚
		æœ¬ç³»çµ±è¨“ç·´è³‡æ–™åŒ…å«å€Ÿç”¨çš„å…¬é–‹å½±åƒè³‡æ–™é›† Rain100Lï¼ˆé›¨çµ²å½±åƒï¼‰ä»¥åŠ NightCity[1]ï¼ˆåŸå¸‚å¤œæ™¯å½±åƒï¼‰ï¼Œä¸¦çµåˆè‡ªè£½ä¹‹ motion blur kernel åˆæˆæ¨¡æ“¬çœŸå¯¦äº¤é€šæƒ…å¢ƒçš„å½±åƒé€€åŒ–ï¼Œä»¥ç¢ºä¿æ¨¡å‹èƒ½åœ¨è¤‡é›œç’°å¢ƒä¸‹è¡¨ç¾ç©©å®šã€‚

NightCity dataset
[1] https://dmcv.sjtu.edu.cn/people/phd/tanxin/NightCity/index.html

## 1) Data Synthesis (`datasynthesis.py`)

### 1.1 Inputs & Notation

* Clean base image <img width="157" height="33" alt="Screenshot 2025-09-29 at 9 29 37â€¯PM" src="https://github.com/user-attachments/assets/10dfa074-b8ee-44a9-8e9f-019a5a0fa8e4" />from NightCity (RGB float32).
* Rain/clean pairs from Rain100L to **extract a rain layer** (R).
* Optional blur kernel (K) and Gaussian noise (n).

* ä¹¾æ·¨åŸºåº•å½±åƒ (C) ä¾†è‡ª NightCityï¼ˆRGBã€float32ã€å€¼åŸŸ ([0,1])ï¼‰ã€‚
* å¾ Rain100L çš„ã€Œé›¨å¤©/ä¹¾æ·¨ã€é…å°ä¸­**ä¼°è¨ˆé›¨å±¤** (R)ã€‚
* å¯é¸ï¼šåŠ å…¥**é‹å‹•æ¨¡ç³Šæ ¸** (K) èˆ‡**é«˜æ–¯é›œè¨Š** (n)ã€‚

---

### 1.2 Rain layer estimation / é›¨å±¤ä¼°è¨ˆ

We estimate a rain-only layer by a simple positive residual between a rainy image (I^{\text{rainy}}) and its clean mate (I^{\text{clean}}) (both in ([0,1])):

[
\boxed{R = \mathrm{clip}\big(I^{\text{rainy}} - I^{\text{clean}},,0,,1\big)} \tag{1}
]
```python
R = (rainy - clean).clamp(0, 1)   # thresholding if needed
```
ç”±é›¨å¤©å½±åƒèˆ‡ä¹¾æ·¨å½±åƒç›¸æ¸›å–æ­£å€¼ï¼Œå¾—åˆ°é›¨å±¤ (R)ï¼Œå†å¤¾ä½æ–¼ ([0,1])ã€‚

---

### 1.3 Low-light rendering by gamma / ä»¥ Î³ èª¿æš—

Nighttime low illumination is synthesized by gamma compression:

[
\boxed{I_{\gamma} = C^{\gamma}}, \qquad \gamma \sim \mathcal{U}(\gamma_{\min},\gamma_{\max}),\ \gamma>1. \tag{2}
]

Typical range: (\gamma\in[1.8,3.0]).

```python
gamma = random.uniform(args.gamma_min, args.gamma_max)  # >>> EDIT HERE <<<
I_gamma = C.clamp(0,1).pow(gamma)
```
ç”¨å†ªæ¬¡ï¼ˆ(\gamma>1)ï¼‰å°‡å½±åƒå£“æš—ï¼Œæ¨¡æ“¬ä½ç…§åº¦ã€‚

---

### 1.4 Rain composition / é›¨å±¤åˆæˆ

We blend the rain layer additively with a strength (s\in[0,1]):

[
\boxed{I_{\text{rain}} = \mathrm{clip}\big(I_{\gamma} + s,R,,0,,1\big)},\quad s\sim\mathcal{U}(s_{\min},s_{\max}). \tag{3}
]

(Optionally alpha-composite via a luminance mask (A) if your code supports it:
(I_{\text{rain}}=(1-A),I_{\gamma} + A,\mathrm{clip}(I_{\gamma}+R,0,1)).)

```python
s = random.uniform(0.5, 1.0)  # >>> EDIT HERE <<<
I_rain = (I_gamma + s*R).clamp(0,1)
```
ä»¥å¼·åº¦ (s) å°‡é›¨å±¤åŠ åˆ°æš—åŒ–å¾Œå½±åƒä¸Šï¼›å¯æ”¹ç‚º alpha åˆæˆã€‚

---

### 1.5 Motion blur / é‹å‹•æ¨¡ç³Š

Convolve with a random linear motion kernel (K) of length (L) and angle (\theta):

[
\boxed{I_{\text{blur}} = K * I_{\text{rain}}},\qquad K = \text{PSF}(L,\theta),\ \sum K=1. \tag{4}
]

```python
L = random.randint(args.blur_len_min, args.blur_len_max)  # >>> EDIT HERE <<<
theta = random.uniform(0,180)
K = make_linear_motion_kernel(L, theta)
I_blur = conv2d_same(I_rain, K)  # normalized kernel
```
ç”¨ç·šæ€§é‹å‹•æ¨¡ç³Šæ ¸å·ç©å½±åƒï¼Œæ ¸é•· (L)ã€è§’åº¦ (\theta)ï¼Œæ ¸é ˆæ­¸ä¸€åŒ–ã€‚

---

### 1.6 Sensor noise / æ„Ÿæ¸¬é›œè¨Š

Add small Gaussian noise (n\sim\mathcal{N}(0,\sigma^2)):

[
\boxed{I_{d} = \mathrm{clip}\big(I_{\text{blur}} + n,,0,,1\big)},\qquad n\sim\mathcal{N}(0,\sigma^2). \tag{5}
]

```python
sigma = args.noise_std  # >>> EDIT HERE <<<
noise = torch.randn_like(I_blur) * sigma
Id = (I_blur + noise).clamp(0,1)
```
åŠ å…¥é«˜æ–¯é›œè¨Šä¸¦å¤¾ä½ç¯„åœï¼Œå¾—åˆ°é€€åŒ–å½±åƒ (I_d)ã€‚**é…å°æ¨™è¨»**å³ç‚º (GT=C)ã€‚

---

### 1.7 Summary of synthesis / åˆæˆæµç¨‹ç¸½çµ

[
\boxed{
I_d = \big(K * (C^{\gamma} + sR)\big) + n \quad \xrightarrow{\ \text{clip}\ } [0,1].
} \tag{6}
]
å…ˆå£“æš—ã€åŠ é›¨ã€å†æ¨¡ç³Šã€åŠ é›œè¨Šï¼Œæœ€å¾Œå¤¾ä½ ([0,1])ã€‚

<img width="309" height="313" alt="image" src="https://github.com/user-attachments/assets/34f46e3f-2a78-4075-bf63-05d7bd51e0d7" />
<img width="309" height="313" alt="image" src="https://github.com/user-attachments/assets/bf1e446e-8783-4c16-93c6-462b32fb77c7" />

---

## 2) Model (`model.py`)

### 2.1 Overall pipeline / æ•´é«”æµç¨‹
<img width="698" height="337" alt="image" src="https://github.com/user-attachments/assets/6b296474-a8c6-43c3-8a2f-fce4abc1a60e" />

1. **Illumination branch (U-Net)** predicts illumination (\hat L).
2. **Retinex division** initializes reflectance (R_0 = \frac{I_d}{\hat L+\varepsilon}).
3. **Reflectance branch** refines reflectance with
   (a) **Spectral Block** (learnable FFT magnitude mask) and
   (b) **GatedFuse** (illumination-guided gating).
4. **Residual compose** forms the restored image.
ä¸Šæ”¯é æ¸¬å…‰ç…§ã€Retinex åˆ†è§£å¾—åˆ°åˆå§‹åå°„ã€ä¸‹æ”¯ä»¥é »åŸŸé®ç½©èˆ‡é–€æ§ç´°åŒ–ï¼Œæœ€å¾Œæ®˜å·®åˆæˆè¼¸å‡ºå¾©åŸåœ–ã€‚

---

### 2.2 Illumination U-Net / å…‰ç…§åˆ†æ”¯

#### Depthwise separable blockï¼ˆDWConvBlockï¼‰

A depthwise conv (W_d) followed by pointwise (1\times1) conv (W_p) and activation:

[
\boxed{
\mathrm{DW}(x)=\phi!\Big(\mathrm{BN}\big(W_p*(W_d \star x)\big)\Big)
} \tag{7}
]

* Encoder: 3 stages .
* Decoder: upsample + skip concat; two DW blocks per stage.
* Head: (1\times1) conv + Sigmoid:

[
\boxed{\hat L = \sigma!\big(W_{1\times1}*F_{\text{dec}}\big)\in[0,1]^{3\times H\times W}} \tag{8}
]
ç”¨ DW å¯å¤§å¹…é™åƒæ•¸èˆ‡ FLOPsï¼›æ¯å€‹ stage ç–Šå…©æ¬¡ DW æ“´å¤§æœ‰æ•ˆæ„Ÿå—é‡èˆ‡è¡¨é”åŠ›ï¼›æœ€å¾Œ (1\times1) + Sigmoid è¼¸å‡ºå…‰ç…§åœ– (\hat L)ã€‚

---

### 2.3 Retinex division / Retinex åˆ†è§£

[
\boxed{R_0=\mathrm{clamp}!\left(\frac{I_d}{\hat L+\varepsilon},,0,,1\right)} \tag{9}
]

```python
eps = 1e-6
R0 = (Id / (L_hat + eps)).clamp(0,1)
```
ä¾ Retinex ç†è«– (I=L!\odot!R)ï¼Œä»¥ (\hat L) è§£è€¦äº®åº¦ï¼Œå¾—åˆ°åˆå§‹åå°„ (R_0)ã€‚

---

### 2.4 Reflectance branch / åå°„åˆ†æ”¯

#### (a) Spectral Blockï¼ˆlearnable FFT magnitude maskï¼‰

At the bottleneck feature (r_3\in\mathbb{R}^{B\times C\times H_s\times W_s}):

[
\begin{aligned}
&z=W_{1\times1}*r_3,\quad X=\mathcal{F}(z)=\mathrm{rfft2}(z) \
&A=\lvert X\rvert,\ \Phi=\angle X,\ \ M=2,\sigma\big(\mathrm{interp}(\Theta)\big)\in(0,2) \
&\tilde A = M\odot A,\quad \tilde X=\tilde A,e^{j\Phi},\quad
z'=\mathcal{F}^{-1}(\tilde X)=\mathrm{irfft2}(\tilde X) \
&\boxed{r_3'=\phi!\big(W'_{1\times1}*z'\big)}
\end{aligned} \tag{10}
]

* Optional **DC lock**: (M[...,0,0]=1).
* Mask resolution ((h,w)) is upsampled to ((H_s, W_s/2+1)).
åœ¨é »åŸŸä»¥å¯å­¸é®ç½© (M) é‡åŠ æ¬Šå¹…å€¼ï¼ˆä¸æ”¹ç›¸ä½ï¼‰ï¼ŒæŠ‘åˆ¶é›¨æ¢çš„çª„å¸¶é »ç‡ï¼Œä¿æŒå¹¾ä½•çµæ§‹ã€‚

#### (b) Illumination-guided GatedFuseï¼ˆtwo scalesï¼‰

For encoder features (r_k) (e.g., (k=2,3)):

[
\boxed{
\text{gate}_k=\sigma!\big(W_g^{(k)} * \mathrm{Resize}(\hat L)\big),\qquad
\tilde r_k=r_k\odot \text{gate}_k.
} \tag{11}
]

```python
# Two gates at e2/e3 scales
r2 = self.gate2(r2, L_hat)  
r3 = self.gate3(r3, L_hat)
```
æŠŠ (\hat L) ä¸‹æ¡æ¨£ä¸¦æŠ•å½±åˆ°ç›¸åŒé€šé“ï¼ŒSigmoid æˆ 0~1 çš„é–€æ§åœ–ï¼Œé€åƒç´ æŠ‘åˆ¶æš—å€/äº®å€çš„éŒ¯èª¤å¢ç›Šã€‚

#### Decoder + head

Upsample + skip concat + DW blocks; head is (1\times1) (+ optional Sigmoid):

[
\boxed{\hat R = \sigma!\big(W^{\text{refl}}*{1\times1}*F^{\text{refl}}*{\text{dec}}\big)\in[0,1]} \tag{12}
]

```python
self.refl_head = nn.Sequential(nn.Conv2d(48,3,1), nn.Sigmoid())
```
è§£ç¢¼å¾Œè¼¸å‡ºåå°„ (\hat R)ï¼›é€šå¸¸é…åˆå€¼åŸŸæ¡ç”¨ Sigmoidã€‚

---

### 2.5 Residual composition / æ®˜å·®åˆæˆ

Instead of directly (\hat L\odot\hat R), we do residual locking to stabilize color/contrast:

[
\boxed{
\hat I = \mathrm{clip}!\big(I_d + (\hat L\odot\hat R - I_d),,0,,1\big).
} \tag{13}
]

```python
I_hat = (Id + (L_hat * R_hat - Id)).clamp(0,1)
```
ä»¥ã€Œæ›¿ä»£åœ– âˆ’ åŸåœ–ã€ç‚ºæ®˜å·®æ›´æ–°ï¼Œé¡è‰²æ›´ç©©å®šã€æ”¶æ–‚è¼ƒå¿«ã€‚

---

## 3) Objective functions / æå¤±å‡½æ•¸

Let (I_{gt}) be the clean GT.

### 3.1 Pixel & SSIMï¼ˆåƒç´ èˆ‡çµæ§‹ç›¸ä¼¼åº¦ï¼‰

[
\boxed{\mathcal{L}*{\text{L1}} = \lVert \hat I - I*{gt}\rVert_1} \tag{14}
]

SSIM (windowed) with constants (C_1, C_2):

[
\boxed{\mathrm{SSIM}(x,y)=\frac{(2\mu_x\mu_y+C_1)(2\sigma_{xy}+C_2)}{(\mu_x^2+\mu_y^2+C_1)(\sigma_x^2+\sigma_y^2+C_2)}},\quad
\mathcal{L}*{\text{SSIM}} = 1-\mathrm{SSIM}(\hat I, I*{gt}). \tag{15}
]
åƒç´  L1 èˆ‡ SSIMï¼ˆä»¥è¦–è¦ºçµæ§‹ä¸€è‡´æ€§ç‚ºä¸»ï¼‰ã€‚

### 3.2 Total variation on illumination / å…‰ç…§å¹³æ»‘ TV

[
\boxed{
\mathcal{L}*{\text{TV}}(\hat L)=
\lambda*{\text{TV}}!\Bigg(\frac{1}{N}!\sum!\lvert \hat L_{i,j+1}-\hat L_{i,j}\rvert +
\frac{1}{N}!\sum!\lvert \hat L_{i+1,j}-\hat L_{i,j}\rvert\Bigg)
} \tag{16}
]
å° (\hat L) åŠ ç¸½è®Šåˆ†ä»¥å»é™¤é‹¸é½’èˆ‡é›œè¨Šã€‚

### 3.3 Spectral magnitude loss / é »å¹…ä¸€è‡´æ€§

[
\boxed{
\mathcal{L}*{\text{spec}}(\hat I, I*{gt})=
\lambda_{\text{spec}},
\big|,\lvert \mathcal{F}(\hat I)\rvert - \lvert \mathcal{F}(I_{gt})\rvert,\big|_1
} \tag{17}
]
ä½¿è¼¸å‡ºèˆ‡ GT åœ¨é »åŸŸå¹…å€¼åˆ†å¸ƒä¸€è‡´ï¼Œæœ‰åŠ©æ–¼å»é™¤é€±æœŸæ€§é›¨æ¢èˆ‡æ¢ç´‹ã€‚

### 3.4 Total loss / ç¸½æå¤±

[
\boxed{
\mathcal{L} =
\lambda_1,\mathcal{L}*{\text{L1}} +
\lambda_2,\mathcal{L}*{\text{SSIM}} +
\lambda_3,\mathcal{L}*{\text{TV}} +
\lambda_4,\mathcal{L}*{\text{spec}}.
} \tag{18}
]

```python
w1,w2,w3,w4 = 1.0, 0.5, 0.1, 0.1
loss = w1*L1 + w2*SSIM + w3*TV(L_hat) + w4*Spec(I_hat, I_gt)
```
å››é …åŠ æ¬Šï¼šåƒç´ ã€çµæ§‹ã€å…‰ç…§å¹³æ»‘ã€é »åŸŸä¸€è‡´ã€‚

---

## 4) Architecture diagram mapping / æ¶æ§‹åœ–å°ç…§

<img width="698" height="337" alt="image" src="https://github.com/user-attachments/assets/6b296474-a8c6-43c3-8a2f-fce4abc1a60e" />

* **Illumination U-Net**

  * Encoder: (3!\to!32!\to!64!\to!128) @ (H!\to!H/2!\to!H/4)
  * Decoder: upsample + skip; head (1\times1) + Sigmoid (\Rightarrow \hat L)
* **Retinex division** (R_0=I_d/(\hat L+\varepsilon))
* **Reflectance encoder** (3!\to!48!\to!96!\to!192)
* **Spectral Block (H/4)** on (C{=}192)
* **GatedFuse** at (H/2) and (H/4)
* **Reflectance decoder** â†’ head (1\times1) (+ Sigmoid) (\Rightarrow \hat R)
* **Residual compose** (\hat I = \mathrm{clip}(I_d + (\hat L\hat R - I_d)))


## ğŸ”¹ æ¶æ§‹å…ƒä»¶è§£é‡‹
1. **Illumination U-Net**
   * **åœ¨åšä»€éº¼**ï¼šé€™å€‹åˆ†æ”¯åƒæ˜¯ã€Œæ‰‹é›»ç­’ã€ï¼Œå°ˆé–€å»ä¼°è¨ˆæ¯å€‹åƒç´ æœ‰å¤šå°‘å…‰ç·šï¼ˆäº®åº¦ï¼‰ã€‚
   * **ç‚ºä»€éº¼é‡è¦**ï¼šæœ‰äº†å…‰ç…§åœ– (\hat L)ï¼Œæˆ‘å€‘å°±èƒ½çŸ¥é“å“ªè£¡æ˜¯æš—å€ã€å“ªè£¡æ˜¯äº®å€ï¼Œé€™æ˜¯å¾Œé¢ Retinex åˆ†è§£å’Œé–€æ§çš„åŸºç¤ã€‚
     
2. **Retinex division**
   * **åœ¨åšä»€éº¼**ï¼šæŠŠåŸå§‹å½±åƒ (I_d) é™¤ä»¥å…‰ç…§ (\hat L)ï¼Œå¾—åˆ°åˆæ­¥çš„æè³ª/åå°„å±¤ (R_0)ã€‚
   * **ç‚ºä»€éº¼é‡è¦**ï¼šé€™ä¸€æ­¥æŠŠã€Œå…‰ã€å’Œã€Œæè³ªã€åˆ†é–‹ï¼Œè®“å¾Œé¢çš„åå°„åˆ†æ”¯ä¸ç”¨å†ç®¡äº®æš—ï¼Œåªå°ˆæ³¨è™•ç†ç´‹ç†å’Œé›¨ç—•ã€‚

3. **Reflectance encoder**
   * **åœ¨åšä»€éº¼**ï¼šé€™æ˜¯åå°„åˆ†æ”¯çš„ç·¨ç¢¼å™¨ï¼Œé€å±¤å£“ç¸®ç‰¹å¾µï¼ŒæŠŠç´°ç¯€ã€ç´‹ç†ã€é›¨ç—•éƒ½æŠ½å–å‡ºä¾†ã€‚
   * **ç‚ºä»€éº¼é‡è¦**ï¼šæŠŠè¤‡é›œçš„æè³ªç‰¹å¾µè¡¨ç¤ºå‡ºä¾†ï¼Œç‰¹åˆ¥æ˜¯é‚£äº›ç´°é•·çš„é›¨æ¢ã€‚

4. **Spectral Block (H/4)**
   * **åœ¨åšä»€éº¼**ï¼šåœ¨é »ç‡ä¸–ç•Œè£¡ç”¨ä¸€å€‹å­¸ç¿’åˆ°çš„æ¿¾æ³¢å™¨ï¼Œå°ˆé–€å£“æ‰ã€Œé›¨æ¢çš„é »ç‡å³°å€¼ã€ã€‚
   * **ç‚ºä»€éº¼é‡è¦**ï¼šé›¨æ¢åœ¨é »åŸŸè£¡æœ‰å›ºå®šçš„çª„å¸¶ç‰¹å¾µï¼Œé€™å€‹æ¨¡çµ„å°±åƒã€Œè€³å¡ã€ï¼ŒæŠŠé‚£ç¨®å™ªéŸ³éæ¿¾æ‰ï¼Œä½†ä¿ç•™ç•«é¢åŸæœ¬çš„å½¢ç‹€ã€‚

5. **GatedFuse (H/2, H/4)**
   * **åœ¨åšä»€éº¼**ï¼šç”¨å…‰ç…§åœ– (\hat L) ç”Ÿæˆã€Œé–˜é–€ã€ï¼Œå‘Šè¨´åå°„åˆ†æ”¯åœ¨æŸäº›å€åŸŸè¦åŠ å¼·ï¼ŒæŸäº›å€åŸŸè¦æŠ‘åˆ¶ã€‚
   * **ç‚ºä»€éº¼é‡è¦**ï¼šæš—çš„åœ°æ–¹é¿å…æ”¾å¤§é›œè¨Šï¼Œäº®çš„åœ°æ–¹é¿å…æŠŠé›¨ç—•èª¤ç•¶ç´‹ç†ï¼Œç›¸ç•¶æ–¼ã€Œå…‰ç…§å°éŠã€å¹«å¿™èª¿æ•´ã€‚

6. **Reflectance decoder**
   * **åœ¨åšä»€éº¼**ï¼šæŠŠå£“ç¸®å¾Œçš„åå°„ç‰¹å¾µå†æ”¾å¤§å›åŸåœ–å¤§å°ï¼Œé‡å»ºå‡ºä¹¾æ·¨çš„åå°„åœ– (\hat R)ã€‚
   * **ç‚ºä»€éº¼é‡è¦**ï¼šé€™ä¸€æ­¥å°±æ˜¯ã€ŒæŠŠæŠ½è±¡ç‰¹å¾µç¿»è­¯å›å½±åƒã€ï¼Œä¸¦ç”¨æœ€å¾Œçš„ 1Ã—1 å·ç© + Sigmoid é™åˆ¶åœ¨æ­£å¸¸çš„ RGB ç¯„åœã€‚

7. **Residual compose**
   * **åœ¨åšä»€éº¼**ï¼šæŠŠåŸåœ– (I_d) å’Œä¿®å¾©å¾Œçš„å…‰ç…§ Ã— åå°„çµæœ (\hat L \hat R) æ··åœ¨ä¸€èµ·ï¼Œç”¨æ®˜å·®æ–¹å¼è¼¸å‡ºæœ€çµ‚å¾©åŸå½±åƒ (\hat I)ã€‚
   * **ç‚ºä»€éº¼é‡è¦**ï¼šé€™æ¨£èƒ½ä¿ç•™é¡è‰²èˆ‡å°æ¯”ï¼Œä¸æœƒä¿®éé ­ï¼Œæ”¶æ–‚ä¹Ÿæ›´ç©©å®šã€‚

ğŸ‘‰ ç™½è©±ç‰ˆï¼š
* ä¸Šé¢é‚£æ¢ U-Net è² è²¬ã€Œçœ‹æ¸…æ¥šå…‰ç…§ã€ã€‚
* Retinex æŠŠã€Œå…‰ã€è·Ÿã€Œæè³ªã€æ‹†é–‹ã€‚
* ä¸‹é¢é‚£æ¢ç·¨ç¢¼å™¨è² è²¬ã€ŒæŠ“ç´°ç¯€ã€æŠ“é›¨ç—•ã€ã€‚
* ä¸­é–“çš„ Spectral Block ç”¨ã€Œé »ç‡æ¿¾æ³¢ã€å»é›¨ã€‚
* GatedFuse ç”¨ã€Œå…‰ç…§ã€ä¾†èª¿æ•´åå°„ç‰¹å¾µã€‚
* è§£ç¢¼å™¨æŠŠåå°„ç´°ç¯€çµ„å›å½±åƒã€‚
* æœ€å¾Œ Residual compose æŠŠä¹¾æ·¨çš„åå°„å’Œå…‰ç…§é‡çµ„ï¼Œè¼¸å‡ºä¸€å¼µç©©å®šçš„æ¸…æ™°å½±åƒã€‚

---

## 5) Code locations to modify / é‡è¦å¯èª¿è™•ï¼ˆè¡Œç‚ºä¸è®Šçš„å®‰å…¨ä¿®æ”¹é»ï¼‰

### `datasynthesis.py`

* **Gamma range**: search `gamma_min`, `gamma_max`.
* **Rain strength**: search `s = random.uniform(`.
* **Blur kernel**: `make_linear_motion_kernel`, change length/angle ranges.
* **Noise std**: search `noise_std`.
* **Clamping**: ensure every stage ends with `.clamp(0,1)`.

### `model.py`

* **Base channels**: `base_illum`, `base_refl`.
* **Spectral Block**: `SpectralBlock(ch=..., height=..., width=..., share_channels=True)`; `fix_dc=True`.
* **GatedFuse scales**: add/remove `gate1/gate2/gate3` and corresponding calls.
* **Heads**: add/remove `nn.Sigmoid()` to control range.
* **Residual compose**: the final `clamp(0,1)` is recommended.

